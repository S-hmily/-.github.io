<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="1.什么是KNN算法

KNN 全称K-nearst neighbors，K近邻算法，是一种典型的监督学习算法。
KNN（K-Nearest Neighbor）算法是机器学习算法中最基础、最简单的算法之一。它既能用于分类，也能用于回归。KN..." />
    <meta name="keywords" content="机器学习" />
    <link rel="stylesheet" href="https://s-hmily.github.io/media/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://s-hmily.github.io/styles/main.css">
    
    <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.1/build/styles/default.min.css">
              
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.1/build/highlight.min.js"></script>
    <script src="https://s-hmily.github.io/media/js/clipboard.min.js"></script>
    <link rel="stylesheet" href="https://s-hmily.github.io/media/css/live2d.css">
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js"></script>
    <!-- 最新版本的 Bootstrap 核心 CSS 文件 -->
    <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.13.1/css/all.min.css" rel="stylesheet">
    <!-- 数学公式 -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css"
        integrity="sha384-9tPv11A+glH/on/wEu99NVwDPwkMQESOocs/ZGXPoIiLE8MU/qkqUcZ3zzL+6DuH" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.js"
        integrity="sha384-U8Vrjwb8fuHMt6ewaCy8uqeUXv4oitYACKdB0VziCerzt011iQ/0TqlSlv8MReCm" crossorigin="anonymous">
    </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/contrib/auto-render.min.js"
        integrity="sha384-aGfk5kvhIq5x1x5YdvCp4upKZYnA8ckafviDpmWEKp4afOZEqOli7gqSnh8I6enH" crossorigin="anonymous">
    </script>
    <script>
        renderMathInElement(document.body, {
            delimiters: [{
                    left: "$$",
                    right: "$$",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                }
            ]
        });
    </script>

    
    <title>叮叮当</title>
    
    <style>
        .markdownIt-TOC {
            padding-left: 2px;
            width: 100%;
        }
        .markdownIt-TOC li{
            padding-left: 2%;
        }
    </style>
    
</head>

<body>
    <!-- 响应式布局，针对PC端内容显示 -->
    <div id="content">
        <div class="nav-large">
            <div class="row">
                <div class="side"><head>
    <meta name="description" content="“你买的什么书？”
“《边城》”
“C++还是python？”
“沈从文”" />
    <link rel="stylesheet" href="https://s-hmily.github.io/media/css/bootstrap.min.css">
</head>


<body>
    



    
    <nav class="navbar navbar-inverse navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <a class="navbar-brand" href="https://s-hmily.github.io"
                    style="font-size:21px">叮叮当&nbsp;&nbsp;|&nbsp;&nbsp;</a>
                <a class="navbar-brand" href=""
                    style="font-size:15px;font-family:kaiti">“你买的什么书？”
“《边城》”
“C++还是python？”
“沈从文”</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse">
                
                <div class="search nav navbar-nav" style="margin-top:8px">
                    <!-- <input type="text" class="search-input" placeholder="标题搜索(●'◡'●)" /> -->
                    <input type="text" class="search-input" placeholder="标题搜索 ⚆_⚆ つ♡">
                    <div class="search-results"></div>
                </div>
                
                <div class="search nav navbar-nav">
                <a title="text" onclick="document.getElementById('socialMenu').style.display='block'"><i><img class="social"
                    src="https://s-hmily.github.io/media/images/social.png" alt=""></i></a>
            </div>
            <ul class="nav navbar-nav" style="float: right;margin-right:5%">
                
                
                <li>
                    <a href="https://s-hmily.github.io" style="color:white">
                        首页
                    </a>
                </li>
                
                
                
                <li>
                    <a href="/archives" style="color:white">
                        归档
                    </a>
                </li>
                
                
                
                <li>
                    <a href="https://s-hmily.github.io/tags" style="color:white">
                        标签
                    </a>
                </li>
                
                
                
                <li><a href="https://s-hmily.github.io/talk" style="color:white;">说说</a></li>
                
                  
                <li><a href="https://s-hmily.github.io/friends" style="color:white">友链</a></li>
                
                  <li><img src="https://s-hmily.github.io/images/avatar.png?v=1595389040161" alt=""
                class="menutopavatar"></li>
            </ul>
        </div><!-- /.navbar-collapse -->
        </div><!-- /.container-fluid -->
    </nav>
    <div id="socialMenu" class="modal">
        <div class="animate">
            <div class="socialContainer">
                
                
                <a onclick="showqq()" style="cursor:pointer"><i><img class="icon" src="https://s-hmily.github.io/media/images/QQ.png"
                            alt=""></i></a>
                
                
                
                
                <a href="LB180928" target="_blank"><i><img class="icon"
                            src="https://s-hmily.github.io/media/images/wechat.png" alt=""></i></a>
                
                
            </div>
            <div id="qq" style="display:none">897438019</div>
        </div>
    </div>
    <!-- 引入jQuery核心js文件 -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js"></script>
    <script>
        var social = document.getElementById('socialMenu');
        // 鼠标点击模型外区域关闭登录框
        window.onclick = function (event) {
            if (event.target == social) {
                social.style.display = "none";
            }
        }
    </script>
    
</body>
<script>
    //-------------------------------------------------搜索
    // 获取搜索框、搜索按钮、清空搜索、结果输出对应的元素
    var searchInput = document.querySelector('.search-input');
    var searchResults = document.querySelector('.search-results');

    // 申明保存文章的标题、链接、内容的数组变量
    var searchValue = '',
        arrItems = [],
        arrLinks = [],
        arrTitles = [],
        arrResults = [],
        indexItem = [],
        itemLength = 0;
    var tmpDiv = document.createElement('div');
    tmpDiv.className = 'result-item';

    // ajax 的兼容写法
    var xhr = new XMLHttpRequest() || new ActiveXObject('Microsoft.XMLHTTP');
    xhr.onreadystatechange = function () {
        if (xhr.readyState == 4 && xhr.status == 200) {
            xml = xhr.responseXML;
            arrItems = xml.getElementsByTagName('entry');
            itemLength = arrItems.length;
            // 遍历并保存所有文章对应的标题、链接、内容到对应的数组中
            // 同时过滤掉 HTML 标签
            for (i = 0; i < itemLength; i++) {
                var link = arrItems[i].getElementsByTagName('link')[0];
                arrLinks[i] = link.getAttribute("href");
                arrTitles[i] = arrItems[i].getElementsByTagName('title')[0].
                childNodes[0].nodeValue.replace(/<.*?>/g, '');
            }
        }
    }

    // 开始获取根目录下 feed.xml 文件内的数据
    xhr.open('get', '/atom.xml', true);
    xhr.send();



    // 输入框内容变化后就开始匹配，可以不用点按钮
    // 经测试，onkeydown, onchange 等方法效果不太理想，
    // 存在输入延迟等问题，最后发现触发 input 事件最理想，
    // 并且可以处理中文输入法拼写的变化
    searchInput.oninput = function () {
        setTimeout(searchConfirm, 0);
    }
    searchInput.onfocus = function () {
        searchResults.style.display = 'block';
    }

    function searchConfirm() {
        if (searchInput.value == '') {
            searchResults.style.display = 'none';
        } else if (searchInput.value.search(/^\s+$/) >= 0) {
            // 检测输入值全是空白的情况
            searchInit();
            var itemDiv = tmpDiv.cloneNode(true);
            itemDiv.innerText = '请输入有效内容...';
            searchResults.appendChild(itemDiv);
        } else {
            // 合法输入值的情况
            searchInit();
            searchValue = searchInput.value;
            // 在标题、内容中查找
            searchMatching(arrTitles, searchValue);
        }
    }

    // 每次搜索完成后的初始化
    function searchInit() {
        arrResults = [];
        indexItem = [];
        searchResults.innerHTML = '';
        searchResults.style.display = 'block';
    }

    function searchMatching(arr1, input) {
        // 忽略输入大小写
        input = new RegExp(input, 'i');
        // 在所有文章标题、内容中匹配查询值
        for (i = 0; i < itemLength; i++) {
            if (arr1[i].search(input) !== -1) {
                var arr = arr1;
                indexItem.push(i); // 保存匹配值的索引
                var indexContent = arr[i].search(input);
                // 此时 input 为 RegExp 格式 /input/i，转换为原 input 字符串长度
                var l = input.toString().length - 3;
                var step = 10;

                // 将匹配到内容的地方进行黄色标记，并包括周围一定数量的文本
                arrResults.push(arr[i].slice(indexContent - step, indexContent));
            }
        }

        // 输出总共匹配到的数目
        var totalDiv = tmpDiv.cloneNode(true);
        totalDiv.innerHTML = '<b>总匹配：' + indexItem.length + ' 项<hr></b>';
        searchResults.appendChild(totalDiv);

        // 未匹配到内容的情况
        if (indexItem.length == 0) {
            var itemDiv = tmpDiv.cloneNode(true);
            itemDiv.innerText = '未匹配到内容...';
            searchResults.appendChild(itemDiv);
        }

        // 将所有匹配内容进行组合
        for (i = 0; i < arrResults.length; i++) {
            var itemDiv = tmpDiv.cloneNode(true);
            itemDiv.innerHTML = '<b>[' + arrTitles[indexItem[i]] +
                ']</b><p>' + arrResults[i] + "</p><hr />";
            itemDiv.setAttribute('onclick', 'changeHref(arrLinks[indexItem[' + i + ']])');
            searchResults.appendChild(itemDiv);
        }
    }

    function changeHref(href) {
        location.href = href;
    }

    function showqq() {
        var qq = document.getElementById("qq").innerHTML;
        if (qq != '')
            alert("博主的QQ联系方式为：" + qq);
        else
            alert("博主暂未设置QQ联系方式");
    }
</script></div>
    
    <div id="main" class="col-xs-12 col-sm-7" style="width:50%;margin-top:50px;left:27%">
        <link rel="stylesheet" href="https://s-hmily.github.io/media/css/font-awesome.css">
<style>

</style>

<body>
    <div class="allcontent" id="postdetail">
        <div class="postshow">
            
            <div class="postdetailimg" style="width:100%;overflow: hidden;display: none">
                <img src="https://s-hmily.github.io/post-images/knn-suan-fa-jie-xi-ji-qi-ying-yong.jpg" class="postimage" style="cursor:auto">
            </div>
            <div class="postinfo-detail">
                <div class="postdate"><i class="fa fa-calendar"></i>2020-07-22</div>
                <div class="poststatus postdate"><i class="fa fa-clock-o"></i> 12 min read</div>
                <div class="posttag">
                    
                    <a href="https://s-hmily.github.io/tag/lMYeCI_cf/" class="postlink">
                        <i class="fa fa-tag"></i> 机器学习
                    </a>
                    
                </div>
            </div>
            
        <div id="texttitle" style="text-align: center">
            <h2>KNN算法解析及其应用</h2>
            <!-- id 将作为查询条件 -->
            <div id="pl" style="display:none">https://s-hmily.github.io/post/knn-suan-fa-jie-xi-ji-qi-ying-yong/</div>
            <div id="rootaddr" style="display:none">https://s-hmily.github.io</div>
            <span id="hotnum" class="leancloud_visitors" data-flag-title="KNN算法解析及其应用">
                <h4 class="readercount">热度🔥: <i class="leancloud-visitors-count">loading...</i></h4>
            </span>
        </div>
        <div class="text ">
            <h2 id="1什么是knn算法">1.什么是KNN算法</h2>
<ul>
<li>KNN 全称K-nearst neighbors，K近邻算法，是一种典型的监督学习算法。</li>
<li>KNN（K-Nearest Neighbor）算法是机器学习算法中最基础、最简单的算法之一。它既能用于分类，也能用于回归。KNN通过测量不同特征值之间的距离来进行分类。</li>
<li>KNN的作用就是对于输入的任意n维向量，可以预判这个n维向量在数据集中的的标签或者预测值，将这个输入样本进行分类</li>
<li>KNN算法是一种非常特别的机器学习算法，因为它没有一般意义上的学习过程。它的工作原理是利用训练数据对特征向量空间进行划分，并将划分结果作为最终算法模型。存在一个样本数据集合，也称作训练样本集，并且样本集中的每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。</li>
<li>输入没有标签的数据后，将这个没有标签的数据的每个特征与样本集中的数据对应的特征进行比较，然后提取样本中特征最相近的数据（最近邻）的分类标签。</li>
<li>一般而言，我们只选择样本数据集中前k个最相似的数据，这就是KNN算法中K的由来，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的类别，作为新数据的分类。</li>
</ul>
<h2 id="2knn算法分析">2.KNN算法分析</h2>
<p>预测过程：对于一个需要预测的输入向量x，我们只需要在训练数据集中寻找k个与向量x最近的向量的集合，然后把x的类别进行预测，把x的类别预测为这k个样本中类别最多的那一类<br>
<img src="https://s-hmily.github.io/post-images/1595388102943.png" alt="" loading="lazy"></p>
<p>如图所示，ω1、ω2、ω3分别代表训练集中的三个类别。其中，与xu最相近的5个点（k=5）如图中箭头所指，很明显与其最相近的5个点中最多的类别为ω1，因此，KNN算法将xu的类别预测为ω1。</p>
<p>算法执行的步骤：</p>
<p>输入：训练数据集</p>
<figure data-type="image" tabindex="1"><img src="https://s-hmily.github.io/post-images/1595388158811.png" alt="" loading="lazy"></figure>
<p>其中： <br>
<img src="https://s-hmily.github.io/post-images/1595388162236.png" alt="" loading="lazy"></p>
<p>为n维的实例特征向量。 <br>
<img src="https://s-hmily.github.io/post-images/1595388168096.png" alt="" loading="lazy"></p>
<p>为实例的类别，其中，i=1,2,…,N，预测实例x。</p>
<p>输出：预测实例x所属类别y。</p>
<p>算法执行步骤：</p>
<ol>
<li>
<p>根据给定的距离量度方法（一般情况下使用欧氏距离）在训练集T中找出与x最相近的k个样本点，并将这k个样本点所表示的集合记为N_k(x)；</p>
</li>
<li>
<p>根据如下所示的多数投票的原则确定实例x所属类别y：</p>
</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://s-hmily.github.io/post-images/1595388203338.png" alt="" loading="lazy"></figure>
<p>上式中I为指示函数：</p>
<figure data-type="image" tabindex="3"><img src="https://s-hmily.github.io/post-images/1595388211534.png" alt="" loading="lazy"></figure>
<h2 id="3影响knn算法的因素">3.影响KNN算法的因素</h2>
<ul>
<li><strong>K值的选择</strong>：K值的确定与样本最终的判定结果有很大的关系；K 值太小会使得 KNN 算法容易过拟合。反之，太大则会欠拟合。因此，一般采用交叉验证的方式选取 K 值。</li>
<li><strong>距离的度量</strong>：通过什么样的距离理论确定最近邻的样本数据。一般使用欧氏距离(欧几里得距离)；</li>
<li><strong>决策规则</strong>：以什么样的决策规则来确定最终的输出结果。 如上图的决策规则是通过“多数表决法”对结果进行分类。<br>
在分类预测时，一般采用“多数表决法”或“加权多数表决法”；<br>
而在做回归预测时，一般采用“平均值法”或“加权平均值法”，这也是KNN做分类与回归最主要的区别。<br>
这里所说的加权一般情况下采用权重和距离成反比的方式来计算。</li>
</ul>
<h3 id="31k值的选择">3.1K值的选择</h3>
<p>KNN算法中只有一个超参数k，k值的确定对KNN算法的预测结果有着至关重要的影响。接下来，我们讨论一下k值大小对算法结果的影响以及一般情况下如何选择k值。</p>
<p>如果k值比较小，相当于我们在较小的领域内训练样本对实例进行预测。这时，算法的近似误差（Approximate Error）会比较小，因为只有与输入实例相近的训练样本才会对预测结果起作用。</p>
<p>但是，它也有明显的缺点：算法的估计误差比较大，预测结果会对近邻点十分敏感，也就是说，如果近邻点是噪声点的话，预测就会出错。因此，k值过小容易导致KNN算法的过拟合。</p>
<p>同理，如果k值选择较大的话，距离较远的训练样本也能够对实例预测结果产生影响。这时候，模型相对比较鲁棒，不会因为个别噪声点对最终预测结果产生影响。但是缺点也十分明显：算法的近邻误差会偏大，距离较远的点（与预测实例不相似）也会同样对预测结果产生影响，使得预测结果产生较大偏差，此时模型容易发生欠拟合。</p>
<p>因此，在实际工程实践中，我们一般采用交叉验证的方式选取k值。通过以上分析可知，一般k值选得比较小，我们会在较小范围内选取k值，同时把测试集上准确率最高的那个确定为最终的算法超参数k。</p>
<h3 id="32距离的度量">3.2距离的度量</h3>
<p>样本空间内的两个点之间的距离量度表示两个样本点之间的相似程度：距离越短，表示相似程度越高；反之，相似程度越低。</p>
<p>常用的距离量度方式包括：</p>
<p>闵可夫斯基距离</p>
<p>欧氏距离</p>
<p>曼哈顿距离</p>
<p>切比雪夫距离</p>
<p>余弦距离</p>
<p>一般机器学习使用的是欧氏距离，具体公式如下图：<br>
平面几何距离公式：<br>
<img src="https://s-hmily.github.io/post-images/1595388350432.png" alt="" loading="lazy"><br>
立体几何距离公式：<br>
<img src="https://s-hmily.github.io/post-images/1595388373349.png" alt="" loading="lazy"><br>
机器学习中高纬度样本的欧拉距离表达：<br>
<img src="https://s-hmily.github.io/post-images/1595388486154.png" alt="" loading="lazy"><br>
机器学习中高纬度样本的欧拉距离表达化简成：<br>
<img src="https://s-hmily.github.io/post-images/1595388542389.png" alt="" loading="lazy"></p>
<h2 id="4knn代码的实现">4.KNN代码的实现</h2>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from math import sqrt

#原始格式的数据
raw_data_X = [[3.393533211, 2.331273381],
              [3.110073483, 1.781539638],
              [1.343808831, 3.368360954],
              [3.582294042, 4.679179110],
              [2.280362439, 2.866990263],
              [7.423436942, 4.696522875],
              [5.745051997, 3.533989803],
              [9.172168622, 2.511101045],
              [7.792783481, 3.424088941],
              [7.939820817, 0.791637231]
             ]
raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]


#转化为方便numpy处理的ndarray类型数据
X_train=np.array(raw_data_X )
y_train=np.array(raw_data_y)

#把训练数据用散点图画出来，其中y_train==0,0表示取出y_train中类别为0的样本点的第1列
#y_train==0,1表示取出y_train中类别为0的样本点的第2列，以此类推
plt.scatter(X_train[y_train==0,0],X_train[y_train==0,1],color='r',s=120)
plt.scatter(X_train[y_train==1,0],X_train[y_train==1,1],color='b',s=120)


#x表示新来的样本点，并将其也画在散点图上
x=np.array([5.876543210,2.491234560])
plt.scatter(x[0],x[1],color='g',s=120)

#distances=[]
#for x_train in X_train:
#    d=sqrt(np.sum((x-x_train)**2))
#    distances.append(d)


#35--38行的循环语句可以用第43行的列表表达式取代，
#此处为求新来样本点与训练样本中所有点的欧氏距离
distances=[sqrt(np.sum((x-x_train)**2)) for x_train in X_train]
print(distances)
print('===========================')

#用argsort方法求距离对应的索引值
nearest=np.argsort(distances)
print(nearest)

k=5

#求距离新来样本点距离最近的K个样本的类别分别是什么【0 or 1】
topK_y=[y_train[i] for i in nearest[:k]]
print('===========================')
print(topK_y)

#用Counter方法分别统计出类别为0和1的个数
votes=Counter(topK_y)
print(votes)

#用most_common求出票数最多的那个样本点的类别
print(votes.most_common(1)[0][0])
</code></pre>
<h2 id="5knn算法的应用基于sklearn自带的数据">5.KNN算法的应用（基于sklearn自带的数据）</h2>
<ul>
<li>基于sklearn自带的红酒数据</li>
<li>基于make方法生成的数据集</li>
</ul>
<h3 id="51针对用sklearn自带的红酒数据">5.1针对用sklearn自带的红酒数据</h3>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_blobs
from sklearn.neighbors import KNeighborsClassifier

#导入sklearn包中自带的红酒数据集所需模块
from sklearn.datasets import load_wine

#导入数据集拆分工具包
from sklearn.model_selection import train_test_split

#导入入sklearn包中自带的红酒数据集
wine_dataset=load_wine()

#查看红酒数据集中的键。其实红酒数据集本质上是一种Bunch对象
#【有点类似于python中的字典】，它包括键（keys）和数值(values)
print('红酒数据集中的KEY键：{}'.format(wine_dataset.keys()))

#查看红酒数据集中的样本数
#print('数据概况:{}'.format(wine_dataset['data'].shape))

#查看红酒数据集中的简单描述
#print(wine_dataset['DESCR'])

#把红酒数据集中的数据拆分为训练数据和测试数据，以及其相应的类别
X_train,X_test,y_train,y_test=train_test_split(wine_dataset['data'],wine_dataset['target'],random_state=2)
print('X_train shape:{}'.format(X_train.shape))
print('X_test shape:{}'.format(X_test.shape))


knn=KNeighborsClassifier(n_neighbors=4)
print('用模型对给定的训练数据进行拟合【学习，训练】')

#把训练数据喂给knn，帮助其拟合出一个机器学习模型
knn.fit(X_train,y_train)
print(knn)

print('模型训练好以后经过测试数据集测试后的得分:{:.2f}'.format(knn.score(X_test,y_test)))

#输入一个新的数据点
X_new=np.array([[13.2,2.77,2.51,18.5,96.6,1.04,2.55,0.57,1.47,6.2,1.05,3.33,820]])

prediction=knn.predict(X_new)
print('=======================')

#给出新样本的分类结果
print('新拿到的红酒经过本模型预测后的类别是:{}'.format(wine_dataset['target_names'][prediction]))
</code></pre>
<h3 id="52针对用make方法生成的数据集">5.2针对用make方法生成的数据集</h3>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

#导入sklearn包中用make方法生成聚类用的数据集所需要用到的模块
from sklearn.datasets import make_blobs

#导入sklearn包中KNN分类算法所需模块
from sklearn.neighbors import KNeighborsClassifier


#用make_blobs方法生成数据集，样本数为200，样本类别为2，随机生成器的种子数为8
data=make_blobs(n_samples=200,centers=2,random_state=8)

#把数据集中的训练数据及训练数据的类别分别赋给X及y
X,y=data

#画散点图，其中c=y的作用是让两类样本分别显示不同颜色以便于区分，cmap是颜色映射表属性
plt.scatter(X[:,0],X[:,1],c=y,cmap=plt.cm.winter)

#生成KNN分类器的一个实例，本质上就是KNN机器学习算法
clf=KNeighborsClassifier()

#把训练数据喂给clf，帮助其拟合出一个机器学习模型
clf.fit(X,y)



x_min,x_max=X[:,0].min()-1,X[:,0].max()+1
y_min,y_max=X[:,1].min()-1,X[:,1].max()+1

#生成网络数据，目的是为下面画分界线的语句pcolormesh提供数据
xx,yy=np.meshgrid(np.arange(x_min,x_max,0.02),
            np.arange(y_min,y_max,0.02))

#np.c_的作用是按行连接两个矩阵，ravel()作用是使矩阵降维，在这里就是展开成一个一维矩阵
Z=clf.predict(np.c_[xx.ravel(),yy.ravel()])

#通过reshape方法使Z的维度和xx一致
Z=Z.reshape(xx.shape)

#画分界线
plt.pcolormesh(xx,yy,Z,cmap=plt.cm.Pastel1)
plt.scatter(X[:,0],X[:,1],c=y,cmap=plt.cm.winter)

plt.scatter(6.75,5.25,c='r',s=200,marker='*')

#给出分类结果
print('新数据点的分类结果是：',clf.predict([[6.75,5.25]]))

#给出分类正确率，但这个例子中的数据集由于我没有把数据进一步
#划分为训练集和测试集，所以其实结果意义不太大
print('该模型的正确率是:{:.2f}'.format(clf.score(X,y)))
</code></pre>

        </div>
        
        
        <div class="next-post">
            下一篇
            <a href="https://s-hmily.github.io/post/juan-ji-shen-jing-wang-luo-de-ying-yong-shi-xian-mnist-shou-xie-ti-shi-bie/">
                卷积神经网络的应用-实现MNIST手写体识别
            </a>
        </div>
        
    </div>
    </div>
</body>
<script>
    var t_img; // 定时�?
    var isLoad = true; // 控制变量
    isImgLoad(function () {
        // 加载完成
        $('.postdetailimg').css("display", "block");
    });
    // 判断图片加载的函�?
    function isImgLoad(callback) {
        // 注意我的图片类名都是cover，因为我�?需要�?�理cover。其它图片可以不管�?
        // 查找所有封面图，迭代�?�理
        $('.postdetailimg').each(function () {
            // 找到�?0就将isLoad设为false，并退出each
            if (this.height === 0) {
                isLoad = false;
                return false;
            }
        });
        // 为true，没有发现为0的。加载完�?
        if (isLoad) {
            clearTimeout(t_img); // 清除定时�?
            // 回调函数
            callback();
            // 为false，因为找到了没有加载完成的图，将调用定时器递归
        } else {
            isLoad = true;
            t_img = setTimeout(function () {
                isImgLoad(callback); // 递归�?�?
            }, 500); // 我这里�?�置的是500�?秒就�?描一次，�?以自己调�?
        }
    }

    //文章阅读热度
    var pl = $("#pl").html();
    var rootaddr = $("#rootaddr").html();
    pl = pl.replace(rootaddr, "");
    $("#hotnum").attr('id', pl);
</script>
        <div name="comment" style="background: white">
            <div class="commentcontainer">
                
                <p>请到客户端“主题--自定义配置--valine”中填入ID和KEY</p>
                
            </div>
        </div>
    </div>
     
                <div class="toc-container">
                    <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1%E4%BB%80%E4%B9%88%E6%98%AFknn%E7%AE%97%E6%B3%95">1.什么是KNN算法</a></li>
<li><a href="#2knn%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90">2.KNN算法分析</a></li>
<li><a href="#3%E5%BD%B1%E5%93%8Dknn%E7%AE%97%E6%B3%95%E7%9A%84%E5%9B%A0%E7%B4%A0">3.影响KNN算法的因素</a>
<ul>
<li><a href="#31k%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9">3.1K值的选择</a></li>
<li><a href="#32%E8%B7%9D%E7%A6%BB%E7%9A%84%E5%BA%A6%E9%87%8F">3.2距离的度量</a></li>
</ul>
</li>
<li><a href="#4knn%E4%BB%A3%E7%A0%81%E7%9A%84%E5%AE%9E%E7%8E%B0">4.KNN代码的实现</a></li>
<li><a href="#5knn%E7%AE%97%E6%B3%95%E7%9A%84%E5%BA%94%E7%94%A8%E5%9F%BA%E4%BA%8Esklearn%E8%87%AA%E5%B8%A6%E7%9A%84%E6%95%B0%E6%8D%AE">5.KNN算法的应用（基于sklearn自带的数据）</a>
<ul>
<li><a href="#51%E9%92%88%E5%AF%B9%E7%94%A8sklearn%E8%87%AA%E5%B8%A6%E7%9A%84%E7%BA%A2%E9%85%92%E6%95%B0%E6%8D%AE">5.1针对用sklearn自带的红酒数据</a></li>
<li><a href="#52%E9%92%88%E5%AF%B9%E7%94%A8make%E6%96%B9%E6%B3%95%E7%94%9F%E6%88%90%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86">5.2针对用make方法生成的数据集</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
    </div>
    </div>
    <div class="toggleContainer">
        <div class="toggle">
            <i class="fas fa-angle-double-up"></i>
        </div>
    </div>
    <div id="bg">
    </div>
    <div id="bgchoice" style="display: none">link</div>
    
    <div id="bgurl" style="display:none">https://pic2.zhimg.com/80/v2-bcbb1a4f932ab78c198b0a99af266d4e_720w.jpg?source=1940ef5c</div>
       
    </div>
    <!-- 响应式布局，针对手机端内容显示 -->
    <div class="nav-small">
        <head>
  <!-- 引入Bootstrap核心样式文件 -->
  <link rel="stylesheet" href="https://s-hmily.github.io/media/css/bootstrap.min.css">
</head>

<body>
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container-fluid">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
          data-target="#barmenu" aria-expanded="false" id="barbutton">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="https://s-hmily.github.io">叮叮当&nbsp;&nbsp;|</a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="barmenu">
        <ul class="nav navbar-nav">
          
          
          <li>
            <a href="https://s-hmily.github.io">
              首页
            </a>
          </li>
          
          
          
          <li>
            <a href="/archives">
              归档
            </a>
          </li>
          
          
          
          <li>
            <a href="https://s-hmily.github.io/tags">
              标签
            </a>
          </li>
          
          
          
            <li><a href="https://s-hmily.github.io/talk">说说</a></li>
            
          
          <li><a href="https://s-hmily.github.io/friends">友链</a></li>

          
        </ul>
      </div><!-- /.navbar-collapse -->
    </div><!-- /.container-fluid -->
  </nav>


  <!-- 引入jQuery核心js文件 -->
  <script src="http://cdn.static.runoob.com/libs/jquery/2.1.1/jquery.min.js"></script>
  <script>
  var btstate = false;
  var bt = $("#barbutton");
  var bm = $("#barmenu");
  bt.click(function(){
    dropdown();
  })
  function dropdown(){
    console.log(btstate);
    //下拉
    if(btstate==false){
      bt.removeClass("collapsed");
      bt.attr("aria-expanded","true");
      bm.attr("aria-expanded","true")
      bm.fadeIn(700);
      btstate = true;
    }
    else{
      bt.addClass("collapsed");
      bt.attr("aria-expanded","false");
      bm.removeClass("in");
      bm.hide();
      bm.attr("aria-expanded","false");
      btstate = false;
    }
  }
  </script> 
</body>
    <div style="margin-top:30px"></div>
    <link rel="stylesheet" href="https://s-hmily.github.io/media/css/font-awesome.css">
<style>

</style>

<body>
    <div class="allcontent" id="postdetail">
        <div class="postshow">
            
            <div class="postdetailimg" style="width:100%;overflow: hidden;display: none">
                <img src="https://s-hmily.github.io/post-images/knn-suan-fa-jie-xi-ji-qi-ying-yong.jpg" class="postimage" style="cursor:auto">
            </div>
            <div class="postinfo-detail">
                <div class="postdate"><i class="fa fa-calendar"></i>2020-07-22</div>
                <div class="poststatus postdate"><i class="fa fa-clock-o"></i> 12 min read</div>
                <div class="posttag">
                    
                    <a href="https://s-hmily.github.io/tag/lMYeCI_cf/" class="postlink">
                        <i class="fa fa-tag"></i> 机器学习
                    </a>
                    
                </div>
            </div>
            
        <div id="texttitle" style="text-align: center">
            <h2>KNN算法解析及其应用</h2>
            <!-- id 将作为查询条件 -->
            <div id="pl" style="display:none">https://s-hmily.github.io/post/knn-suan-fa-jie-xi-ji-qi-ying-yong/</div>
            <div id="rootaddr" style="display:none">https://s-hmily.github.io</div>
            <span id="hotnum" class="leancloud_visitors" data-flag-title="KNN算法解析及其应用">
                <h4 class="readercount">热度🔥: <i class="leancloud-visitors-count">loading...</i></h4>
            </span>
        </div>
        <div class="text ">
            <h2 id="1什么是knn算法">1.什么是KNN算法</h2>
<ul>
<li>KNN 全称K-nearst neighbors，K近邻算法，是一种典型的监督学习算法。</li>
<li>KNN（K-Nearest Neighbor）算法是机器学习算法中最基础、最简单的算法之一。它既能用于分类，也能用于回归。KNN通过测量不同特征值之间的距离来进行分类。</li>
<li>KNN的作用就是对于输入的任意n维向量，可以预判这个n维向量在数据集中的的标签或者预测值，将这个输入样本进行分类</li>
<li>KNN算法是一种非常特别的机器学习算法，因为它没有一般意义上的学习过程。它的工作原理是利用训练数据对特征向量空间进行划分，并将划分结果作为最终算法模型。存在一个样本数据集合，也称作训练样本集，并且样本集中的每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。</li>
<li>输入没有标签的数据后，将这个没有标签的数据的每个特征与样本集中的数据对应的特征进行比较，然后提取样本中特征最相近的数据（最近邻）的分类标签。</li>
<li>一般而言，我们只选择样本数据集中前k个最相似的数据，这就是KNN算法中K的由来，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的类别，作为新数据的分类。</li>
</ul>
<h2 id="2knn算法分析">2.KNN算法分析</h2>
<p>预测过程：对于一个需要预测的输入向量x，我们只需要在训练数据集中寻找k个与向量x最近的向量的集合，然后把x的类别进行预测，把x的类别预测为这k个样本中类别最多的那一类<br>
<img src="https://s-hmily.github.io/post-images/1595388102943.png" alt="" loading="lazy"></p>
<p>如图所示，ω1、ω2、ω3分别代表训练集中的三个类别。其中，与xu最相近的5个点（k=5）如图中箭头所指，很明显与其最相近的5个点中最多的类别为ω1，因此，KNN算法将xu的类别预测为ω1。</p>
<p>算法执行的步骤：</p>
<p>输入：训练数据集</p>
<figure data-type="image" tabindex="1"><img src="https://s-hmily.github.io/post-images/1595388158811.png" alt="" loading="lazy"></figure>
<p>其中： <br>
<img src="https://s-hmily.github.io/post-images/1595388162236.png" alt="" loading="lazy"></p>
<p>为n维的实例特征向量。 <br>
<img src="https://s-hmily.github.io/post-images/1595388168096.png" alt="" loading="lazy"></p>
<p>为实例的类别，其中，i=1,2,…,N，预测实例x。</p>
<p>输出：预测实例x所属类别y。</p>
<p>算法执行步骤：</p>
<ol>
<li>
<p>根据给定的距离量度方法（一般情况下使用欧氏距离）在训练集T中找出与x最相近的k个样本点，并将这k个样本点所表示的集合记为N_k(x)；</p>
</li>
<li>
<p>根据如下所示的多数投票的原则确定实例x所属类别y：</p>
</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://s-hmily.github.io/post-images/1595388203338.png" alt="" loading="lazy"></figure>
<p>上式中I为指示函数：</p>
<figure data-type="image" tabindex="3"><img src="https://s-hmily.github.io/post-images/1595388211534.png" alt="" loading="lazy"></figure>
<h2 id="3影响knn算法的因素">3.影响KNN算法的因素</h2>
<ul>
<li><strong>K值的选择</strong>：K值的确定与样本最终的判定结果有很大的关系；K 值太小会使得 KNN 算法容易过拟合。反之，太大则会欠拟合。因此，一般采用交叉验证的方式选取 K 值。</li>
<li><strong>距离的度量</strong>：通过什么样的距离理论确定最近邻的样本数据。一般使用欧氏距离(欧几里得距离)；</li>
<li><strong>决策规则</strong>：以什么样的决策规则来确定最终的输出结果。 如上图的决策规则是通过“多数表决法”对结果进行分类。<br>
在分类预测时，一般采用“多数表决法”或“加权多数表决法”；<br>
而在做回归预测时，一般采用“平均值法”或“加权平均值法”，这也是KNN做分类与回归最主要的区别。<br>
这里所说的加权一般情况下采用权重和距离成反比的方式来计算。</li>
</ul>
<h3 id="31k值的选择">3.1K值的选择</h3>
<p>KNN算法中只有一个超参数k，k值的确定对KNN算法的预测结果有着至关重要的影响。接下来，我们讨论一下k值大小对算法结果的影响以及一般情况下如何选择k值。</p>
<p>如果k值比较小，相当于我们在较小的领域内训练样本对实例进行预测。这时，算法的近似误差（Approximate Error）会比较小，因为只有与输入实例相近的训练样本才会对预测结果起作用。</p>
<p>但是，它也有明显的缺点：算法的估计误差比较大，预测结果会对近邻点十分敏感，也就是说，如果近邻点是噪声点的话，预测就会出错。因此，k值过小容易导致KNN算法的过拟合。</p>
<p>同理，如果k值选择较大的话，距离较远的训练样本也能够对实例预测结果产生影响。这时候，模型相对比较鲁棒，不会因为个别噪声点对最终预测结果产生影响。但是缺点也十分明显：算法的近邻误差会偏大，距离较远的点（与预测实例不相似）也会同样对预测结果产生影响，使得预测结果产生较大偏差，此时模型容易发生欠拟合。</p>
<p>因此，在实际工程实践中，我们一般采用交叉验证的方式选取k值。通过以上分析可知，一般k值选得比较小，我们会在较小范围内选取k值，同时把测试集上准确率最高的那个确定为最终的算法超参数k。</p>
<h3 id="32距离的度量">3.2距离的度量</h3>
<p>样本空间内的两个点之间的距离量度表示两个样本点之间的相似程度：距离越短，表示相似程度越高；反之，相似程度越低。</p>
<p>常用的距离量度方式包括：</p>
<p>闵可夫斯基距离</p>
<p>欧氏距离</p>
<p>曼哈顿距离</p>
<p>切比雪夫距离</p>
<p>余弦距离</p>
<p>一般机器学习使用的是欧氏距离，具体公式如下图：<br>
平面几何距离公式：<br>
<img src="https://s-hmily.github.io/post-images/1595388350432.png" alt="" loading="lazy"><br>
立体几何距离公式：<br>
<img src="https://s-hmily.github.io/post-images/1595388373349.png" alt="" loading="lazy"><br>
机器学习中高纬度样本的欧拉距离表达：<br>
<img src="https://s-hmily.github.io/post-images/1595388486154.png" alt="" loading="lazy"><br>
机器学习中高纬度样本的欧拉距离表达化简成：<br>
<img src="https://s-hmily.github.io/post-images/1595388542389.png" alt="" loading="lazy"></p>
<h2 id="4knn代码的实现">4.KNN代码的实现</h2>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from math import sqrt

#原始格式的数据
raw_data_X = [[3.393533211, 2.331273381],
              [3.110073483, 1.781539638],
              [1.343808831, 3.368360954],
              [3.582294042, 4.679179110],
              [2.280362439, 2.866990263],
              [7.423436942, 4.696522875],
              [5.745051997, 3.533989803],
              [9.172168622, 2.511101045],
              [7.792783481, 3.424088941],
              [7.939820817, 0.791637231]
             ]
raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]


#转化为方便numpy处理的ndarray类型数据
X_train=np.array(raw_data_X )
y_train=np.array(raw_data_y)

#把训练数据用散点图画出来，其中y_train==0,0表示取出y_train中类别为0的样本点的第1列
#y_train==0,1表示取出y_train中类别为0的样本点的第2列，以此类推
plt.scatter(X_train[y_train==0,0],X_train[y_train==0,1],color='r',s=120)
plt.scatter(X_train[y_train==1,0],X_train[y_train==1,1],color='b',s=120)


#x表示新来的样本点，并将其也画在散点图上
x=np.array([5.876543210,2.491234560])
plt.scatter(x[0],x[1],color='g',s=120)

#distances=[]
#for x_train in X_train:
#    d=sqrt(np.sum((x-x_train)**2))
#    distances.append(d)


#35--38行的循环语句可以用第43行的列表表达式取代，
#此处为求新来样本点与训练样本中所有点的欧氏距离
distances=[sqrt(np.sum((x-x_train)**2)) for x_train in X_train]
print(distances)
print('===========================')

#用argsort方法求距离对应的索引值
nearest=np.argsort(distances)
print(nearest)

k=5

#求距离新来样本点距离最近的K个样本的类别分别是什么【0 or 1】
topK_y=[y_train[i] for i in nearest[:k]]
print('===========================')
print(topK_y)

#用Counter方法分别统计出类别为0和1的个数
votes=Counter(topK_y)
print(votes)

#用most_common求出票数最多的那个样本点的类别
print(votes.most_common(1)[0][0])
</code></pre>
<h2 id="5knn算法的应用基于sklearn自带的数据">5.KNN算法的应用（基于sklearn自带的数据）</h2>
<ul>
<li>基于sklearn自带的红酒数据</li>
<li>基于make方法生成的数据集</li>
</ul>
<h3 id="51针对用sklearn自带的红酒数据">5.1针对用sklearn自带的红酒数据</h3>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_blobs
from sklearn.neighbors import KNeighborsClassifier

#导入sklearn包中自带的红酒数据集所需模块
from sklearn.datasets import load_wine

#导入数据集拆分工具包
from sklearn.model_selection import train_test_split

#导入入sklearn包中自带的红酒数据集
wine_dataset=load_wine()

#查看红酒数据集中的键。其实红酒数据集本质上是一种Bunch对象
#【有点类似于python中的字典】，它包括键（keys）和数值(values)
print('红酒数据集中的KEY键：{}'.format(wine_dataset.keys()))

#查看红酒数据集中的样本数
#print('数据概况:{}'.format(wine_dataset['data'].shape))

#查看红酒数据集中的简单描述
#print(wine_dataset['DESCR'])

#把红酒数据集中的数据拆分为训练数据和测试数据，以及其相应的类别
X_train,X_test,y_train,y_test=train_test_split(wine_dataset['data'],wine_dataset['target'],random_state=2)
print('X_train shape:{}'.format(X_train.shape))
print('X_test shape:{}'.format(X_test.shape))


knn=KNeighborsClassifier(n_neighbors=4)
print('用模型对给定的训练数据进行拟合【学习，训练】')

#把训练数据喂给knn，帮助其拟合出一个机器学习模型
knn.fit(X_train,y_train)
print(knn)

print('模型训练好以后经过测试数据集测试后的得分:{:.2f}'.format(knn.score(X_test,y_test)))

#输入一个新的数据点
X_new=np.array([[13.2,2.77,2.51,18.5,96.6,1.04,2.55,0.57,1.47,6.2,1.05,3.33,820]])

prediction=knn.predict(X_new)
print('=======================')

#给出新样本的分类结果
print('新拿到的红酒经过本模型预测后的类别是:{}'.format(wine_dataset['target_names'][prediction]))
</code></pre>
<h3 id="52针对用make方法生成的数据集">5.2针对用make方法生成的数据集</h3>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

#导入sklearn包中用make方法生成聚类用的数据集所需要用到的模块
from sklearn.datasets import make_blobs

#导入sklearn包中KNN分类算法所需模块
from sklearn.neighbors import KNeighborsClassifier


#用make_blobs方法生成数据集，样本数为200，样本类别为2，随机生成器的种子数为8
data=make_blobs(n_samples=200,centers=2,random_state=8)

#把数据集中的训练数据及训练数据的类别分别赋给X及y
X,y=data

#画散点图，其中c=y的作用是让两类样本分别显示不同颜色以便于区分，cmap是颜色映射表属性
plt.scatter(X[:,0],X[:,1],c=y,cmap=plt.cm.winter)

#生成KNN分类器的一个实例，本质上就是KNN机器学习算法
clf=KNeighborsClassifier()

#把训练数据喂给clf，帮助其拟合出一个机器学习模型
clf.fit(X,y)



x_min,x_max=X[:,0].min()-1,X[:,0].max()+1
y_min,y_max=X[:,1].min()-1,X[:,1].max()+1

#生成网络数据，目的是为下面画分界线的语句pcolormesh提供数据
xx,yy=np.meshgrid(np.arange(x_min,x_max,0.02),
            np.arange(y_min,y_max,0.02))

#np.c_的作用是按行连接两个矩阵，ravel()作用是使矩阵降维，在这里就是展开成一个一维矩阵
Z=clf.predict(np.c_[xx.ravel(),yy.ravel()])

#通过reshape方法使Z的维度和xx一致
Z=Z.reshape(xx.shape)

#画分界线
plt.pcolormesh(xx,yy,Z,cmap=plt.cm.Pastel1)
plt.scatter(X[:,0],X[:,1],c=y,cmap=plt.cm.winter)

plt.scatter(6.75,5.25,c='r',s=200,marker='*')

#给出分类结果
print('新数据点的分类结果是：',clf.predict([[6.75,5.25]]))

#给出分类正确率，但这个例子中的数据集由于我没有把数据进一步
#划分为训练集和测试集，所以其实结果意义不太大
print('该模型的正确率是:{:.2f}'.format(clf.score(X,y)))
</code></pre>

        </div>
        
        
        <div class="next-post">
            下一篇
            <a href="https://s-hmily.github.io/post/juan-ji-shen-jing-wang-luo-de-ying-yong-shi-xian-mnist-shou-xie-ti-shi-bie/">
                卷积神经网络的应用-实现MNIST手写体识别
            </a>
        </div>
        
    </div>
    </div>
</body>
<script>
    var t_img; // 定时�?
    var isLoad = true; // 控制变量
    isImgLoad(function () {
        // 加载完成
        $('.postdetailimg').css("display", "block");
    });
    // 判断图片加载的函�?
    function isImgLoad(callback) {
        // 注意我的图片类名都是cover，因为我�?需要�?�理cover。其它图片可以不管�?
        // 查找所有封面图，迭代�?�理
        $('.postdetailimg').each(function () {
            // 找到�?0就将isLoad设为false，并退出each
            if (this.height === 0) {
                isLoad = false;
                return false;
            }
        });
        // 为true，没有发现为0的。加载完�?
        if (isLoad) {
            clearTimeout(t_img); // 清除定时�?
            // 回调函数
            callback();
            // 为false，因为找到了没有加载完成的图，将调用定时器递归
        } else {
            isLoad = true;
            t_img = setTimeout(function () {
                isImgLoad(callback); // 递归�?�?
            }, 500); // 我这里�?�置的是500�?秒就�?描一次，�?以自己调�?
        }
    }

    //文章阅读热度
    var pl = $("#pl").html();
    var rootaddr = $("#rootaddr").html();
    pl = pl.replace(rootaddr, "");
    $("#hotnum").attr('id', pl);
</script>
    <div name="comment" style="background: white;margin-top:100px">
        <div class="commentcontainer">
            
            <p>请到客户端“主题--自定义配置--valine”中填入ID和KEY</p>
            
        </div>
    </div>
    </div>
    <div id="landlord">
        <div class="message" style="opacity:0"></div>
        <canvas id="live2d" width="240" height="250" class="live2d"></canvas>
    </div>
    <div id="codeCopyText" style="display: none">代码复制成功了哦</div>
    <div id="domainname" style="display:none">https://s-hmily.github.io</div>
    </body>
    <script src="https://s-hmily.github.io/media/js/post.js"></script>
    <script>
        //寻找所有code标签，加复制按钮鸭！(行内代码除外)
        var codes = document.getElementsByTagName('code');
        if (codes.length) {
            for (var i = 0; i < codes.length; i++) {
                //高度/行高=文本行数
                // var rowNum=Math.round(codes[i].height()/parseFloat(codes[i].css('line-height')));
                // console.log("当前有"+rowNum+"行");
                var code_id = "code_id_" + i;
                codes[i].setAttribute("id", code_id);
                var ci = "#" + code_id;
                var codedot = $(ci);
                var rowNum = Math.round(codedot.height() / parseFloat(codedot.css('line-height')));
                if (rowNum <= 1) continue;
                var btn = document.createElement("button");
                btn.setAttribute("class", "copybt");
                btn.setAttribute("data-clipboard-target", "#" + code_id);
                btn.innerHTML = '复制代码';
                codes[i].parentNode.insertBefore(btn, codes[i]);
            }
        };
        var cop = new ClipboardJS('.copybt');
        var codeCopyText = $("#codeCopyText").html();
        cop.on('success', function (e) {
            alert(codeCopyText);
            e.clearSelection();
        });
        cop.on('error', function (e) {
            alert("矮油，复制失败了...手动复制吧勇士！");
            e.clearSelection();
        });
    </script>
    
    <script type="text/javascript">
        var message_Path = '/live2d/'
        var home_Path = document.getElementById("domainname").innerHTML+"/"; //此处修改为你的域名，必须带斜杠
    </script>
    <script type="text/javascript" src="https://s-hmily.github.io/media/live2d/js/live2d.js"></script>
    <script type="text/javascript" src="https://s-hmily.github.io/media/live2d/js/message.js"></script>
    <script type="text/javascript">
        loadlive2d("live2d", "https://s-hmily.github.io/media/live2d/assets/tororo.model.json");
    </script>
    
<script>
$(function () {
    $('.toggleContainer').click(function(){$('html,body').animate({scrollTop: '0px'}, 800);});
	$(window).scroll(function() {
        var st = $(window).scrollTop();
        if(st > 30){
            $(".toggleContainer").fadeIn(400);
        }else{
            $(".toggleContainer").fadeOut(100);
        }
	});
});
</script>

<script>
        var bgchoice=$('#bgchoice').html();
        var bg = $('#bg');
        var bgurl = document.getElementById("bgurl").innerHTML;
        if(bgchoice=='default')
            for (var i = 0; i < 3; i++)
                bgurl = bgurl.replace("\\", "/");
        bg.css("background", "url('" + bgurl + "')");
</script>
