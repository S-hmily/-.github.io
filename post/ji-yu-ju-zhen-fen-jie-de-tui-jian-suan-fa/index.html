<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>基于矩阵分解的推荐算法 | 叮叮当</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://s-hmily.github.io/favicon.ico?v=1594736479293">
<link rel="stylesheet" href="https://s-hmily.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="矩阵分解算法是学习协同过滤算法的基础，接下来就来讲一件什么是矩阵分解。
一，基于矩阵分解算法的相关理论介绍
很显然，我们要是想做推荐系统，最基本的一个数据就是用户对这个商品的特性的反应，就拿用户-物品的评分矩阵来说

矩阵中，描述了五个用户..." />
    <meta name="keywords" content="" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://s-hmily.github.io">
        <img src="https://s-hmily.github.io/images/avatar.png?v=1594736479293" class="site-logo">
        <h1 class="site-title">叮叮当</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="https://s-hmily.github.io" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      叮当
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://s-hmily.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">基于矩阵分解的推荐算法</h2>
            <div class="post-date">2020-07-14</div>
            
            <div class="post-content" v-pre>
              <p>矩阵分解算法是学习协同过滤算法的基础，接下来就来讲一件什么是矩阵分解。<br>
一，基于矩阵分解算法的相关理论介绍<br>
很显然，我们要是想做推荐系统，最基本的一个数据就是用户对这个商品的特性的反应，就拿用户-物品的评分矩阵来说<br>
<img src="https://img-blog.csdnimg.cn/20200713205030760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MTc3OTYw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
矩阵中，描述了五个用户（U1,U2,U3,U4,U5）对四个物品（D1,D2,D3,D4）的评分，但是我们发现有些表格中没有填写评分<br>
的数字，这个时候我们就需要把没有填写的评分根据已知的分数进行预测，然后根据评分的高低给用户进行推荐。<br>
那么如何进行预测缺失的评分呢？那么我们可以把这些想象成点，然后可以根据梯度下降跟回归方程进行连续值的预测。假设是M<em>N维矩阵（M行N列），然后我们可以分解成P矩阵和Q矩阵，其中P矩阵是M</em>K,Q矩阵维度是K*N。（K是过渡数值，也就是过渡维度）<br>
<img src="https://img-blog.csdnimg.cn/20200713210022150.png" alt="图一" loading="lazy"><br>
对于P,Q矩阵的解释，直观上是M个用户对K个主题的关系，Q矩阵是K个主题对N个物品的关系，具体K是多少，这就需要自己的调节了，K只是一个参数，通常取值在10到100之间<br>
<img src="https://img-blog.csdnimg.cn/2020071321100480.png" alt="在这里插入图片描述" loading="lazy"><br>
式子2</p>
<p>其中r代表 R原始矩阵，p，q代表P,Q矩阵。rij代表R矩阵第i行第j列的数字，后边的同理<br>
我们对于矩阵的知识可以知道，这个矩阵i行j列的数值等于P矩阵i行的所有数值乘以q第j列的所有数值的和<br>
然后我们可以知道回归方程的最小二乘法的公式如下<br>
然后把式子2带入式子3中得到下图<br>
<img src="https://img-blog.csdnimg.cn/20200713210437802.png" alt="在这里插入图片描述" loading="lazy"><br>
式子3</p>
<p>对于损失函数的左边项，表示的是R^ 第i行，第j列的元素值，对于如何衡量，我们分解的好坏呢，式子3，给出了衡量标准，也就是损失函数，平方项损失，最后的目标，就是每一个元素(非缺失值)的e(i,j)的总和最小<br>
然后我们需要用到L2正则化<br>
<img src="https://img-blog.csdnimg.cn/20200713211252210.png" alt="在这里插入图片描述" loading="lazy"><br>
因此最终的损失函数为：<br>
<img src="https://img-blog.csdnimg.cn/20200713211530742.png" alt="在这里插入图片描述" loading="lazy"><br>
然后可以使用梯度下降算法对其求解P矩阵和Q矩阵<img src="https://img-blog.csdnimg.cn/20200713211609666.png" alt="在这里插入图片描述" loading="lazy"><br>
最后结果为：<br>
<img src="https://img-blog.csdnimg.cn/20200713211625329.png" alt="在这里插入图片描述" loading="lazy"><br>
代码如下：</p>
<pre><code class="language-cpp">
import numpy as np

#  original_matrix --&gt; P*Q=R
def matrix_factorization(original_matrix, K, alpha, beta, epochs):
    '''
    :param original_matrix(mat): 原始矩阵
    :param K(int): 分解矩阵中间维度
    :param alpha(float): 学习率
    :param beta(float): 惩罚性系数
    :param epochs(int): 最大迭代次数
    :return: 分解后的两个矩阵P,Q
    '''
    original_matrix = np.mat(original_matrix)
    #np.mat 生成矩阵
    M, N = original_matrix.shape
    #np.shape 获取矩阵的行数和列数，然后赋值给M,N  即M代表行数 N代表列数
    P = np.mat(np.random.random((M, K)))
    Q = np.mat(np.random.random((K, N)))
    #np.random.random((M,K))  生成M行K列的浮点数 ，搭配上mat 也就是生成矩阵
    print(&quot;.................&quot;)
    print(P,Q)
    print(&quot;.................&quot;)
    loss = 1.0
    epoch = 0
    while loss &gt;= 0.001 and epoch &lt;= epochs:
        for m in range(M):
            for n in range(N):
                if original_matrix[m, n] &gt; 0:  # 非缺失值
                    r = original_matrix[m, n]
                    r_ = 0  # R[m, n]
                    for k in range(K):  # 计算[m, n]位置的误差
                        r_ += P[m, k]*Q[k, n]
                    e = r - r_
                    for k in range(K):  # 更新P[m, :]与Q[:, n]的值
                        P[m, k] += alpha*(2*e*Q[k, n]-beta*P[m, k])
                        Q[k, n] += alpha*(2*e*P[m, k]-beta*Q[k, n])
        loss = 0.0
        for m in range(M):
            for n in range(N):
                if original_matrix[m, n] &gt; 0:
                    r = original_matrix[m, n]
                    r_ = 0.0
                    regularization = 0.0
                    for k in range(K):
                        r_ += P[m, k]*Q[k, n]  # 偏差
                        regularization += P[m, k]**2+Q[k, n]**2  # L2正则化
                    e = r - r_
                    loss += e**2 + (beta/2)*regularization  # 总损失
        # if epoch % 200 == 0:
        #     print('epoch:{}, loss: {}'.format(epoch, loss))
        epoch += 1
    return P, Q


if __name__ == '__main__':
    low, high = 1, 10
    size = 10, 8
    original_matrix = np.random.randint(low=low, high=high, size=size)
    missing_rate = 0.3
    n_counts = int(size[0]*size[1]*missing_rate)
    while n_counts:
        pos = np.random.randint(size[0]*size[1])
        row, col = pos//size[1], pos%size[1]
        if original_matrix[row, col] != 0:
            original_matrix[row, col] = 0
            n_counts -= 1
    # print(original_matrix)
    P, Q = matrix_factorization(original_matrix, 6, 0.004, 0.02, 12000)
    print(np.dot(P, Q))
</code></pre>
<p>参考：<br>
<a href="https://blog.csdn.net/recall_tomorrow/article/details/80218051">文章一</a><br>
<a href="https://www.cnblogs.com/kobedeshow/p/3651833.html">文章二</a></p>

            </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://s-hmily.github.io/post/ji-yu-yong-hu-de-xie-tong-guo-lu-suan-fa/">
                  <h3 class="post-title">
                    基于用户的协同过滤算法
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
